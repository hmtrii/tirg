{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compute_recall.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmtrii/tirg/blob/main/Compute_recall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj0J6YbZCkHK"
      },
      "source": [
        "#Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xweYyWyaClyg"
      },
      "source": [
        "!rm -rf /content/Fashion200k\n",
        "!mkdir /content/Fashion200k\n",
        "!mkdir /content/Fashion200k/women"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NppLT3yiGAK0",
        "outputId": "5acb4df9-f411-43b3-f450-e325945c1c4b"
      },
      "source": [
        "# Download tập labesl và test_queries.txt\n",
        "!gdown \"https://drive.google.com/uc?id=1-NA4vTjXCdpC-a14bITfU2LxbzpGecQ7\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-NA4vTjXCdpC-a14bITfU2LxbzpGecQ7\n",
            "To: /content/labels_and_test_queries.zip\n",
            "\r0.00B [00:00, ?B/s]\r2.81MB [00:00, 43.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWsDoj-7HDge",
        "outputId": "a88158ac-c611-4608-ac0f-1a07a8324eba"
      },
      "source": [
        "!unzip /content/labels_and_test_queries.zip -d /content/Fashion200k"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/labels_and_test_queries.zip\n",
            "   creating: /content/Fashion200k/labels/\n",
            "  inflating: /content/Fashion200k/labels/pants_test_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/labels/dress_train_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/labels/skirt_train_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/labels/top_train_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/labels/dress_test_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/labels/top_test_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/labels/jacket_train_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/labels/skirt_test_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/labels/pants_train_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/labels/jacket_test_detect_all.txt  \n",
            "  inflating: /content/Fashion200k/test_queries.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU0ESBg5FWIM",
        "outputId": "4f2ea20c-d869-42d8-a32c-b9b2dd2549b9"
      },
      "source": [
        "#Download hình ảnh\n",
        "!gdown \"https://drive.google.com/uc?id=0B4Eo9mft9jwoc20xdkQ0UmtGUGM\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B4Eo9mft9jwoc20xdkQ0UmtGUGM\n",
            "To: /content/women.tar.gz\n",
            "5.86GB [01:53, 51.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUl8jUmcCok2"
      },
      "source": [
        "!tar -xf /content/women.tar.gz -C /content/Fashion200k/women"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1PJ97IZEnA3",
        "outputId": "a26218c1-b351-40b2-b0a2-9d4648b8cc0c"
      },
      "source": [
        "#Download pretrained model\n",
        "!gdown \"https://drive.google.com/uc?id=1-pzLmtStfZZjxlNznZ_Fx_OK_93qDDR4\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-pzLmtStfZZjxlNznZ_Fx_OK_93qDDR4\n",
            "To: /content/best_checkpoint.pth\n",
            "75.2MB [00:00, 240MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VdNhm3iHQMo",
        "outputId": "e279be06-d246-4c35-8027-53c70feba305"
      },
      "source": [
        "# Download các pre-computed\n",
        "!gdown \"https://drive.google.com/uc?id=1-OihRljbJpvfkz5Nyh7YLkD6LOQ5U8eV\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OihRljbJpvfkz5Nyh7YLkD6LOQ5U8eV\n",
            "To: /content/pkls.zip\n",
            "223MB [00:02, 89.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGKTkh4WIHhr",
        "outputId": "3925bf0e-579b-4f42-a79c-247c8aec4994"
      },
      "source": [
        "!unzip /content/pkls.zip -d /content/pkls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/pkls.zip\n",
            "  inflating: /content/pkls/all_captions.pkl  \n",
            "  inflating: /content/pkls/all_imgs.pkl  \n",
            "  inflating: /content/pkls/all_norm_imgs_feature.pkl  \n",
            "  inflating: /content/pkls/all_norm_queries_feature.pkl  \n",
            "  inflating: /content/pkls/all_queries.pkl  \n",
            "  inflating: /content/pkls/all_target_captions.pkl  \n",
            "  inflating: /content/pkls/img_ids.pkl  \n",
            "  inflating: /content/pkls/mods.pkl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLwLuW2_dWRp"
      },
      "source": [
        "# INSTALL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AfCDwglHa42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa276141-c7ab-47cd-94ef-74cb9f64a68f"
      },
      "source": [
        "!git clone https://github.com/hmtrii/tirg.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tirg'...\n",
            "remote: Enumerating objects: 156, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 156 (delta 85), reused 102 (delta 42), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (156/156), 8.89 MiB | 7.73 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9b8NIwraH8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf033cf-ff8a-4560-af55-df46673039d4"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\r\u001b[K     |█                               | 10kB 30.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 31.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 20.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 13.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 13.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 13.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 13.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 13.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 13.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 13.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 13.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 13.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 13.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 13.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 13.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 13.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 13.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 13.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 13.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.19.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (51.1.1)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RarrJevA66j8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8eb0b1-1034-4a74-d24d-6aedb3996829"
      },
      "source": [
        "!pip install torch==1.2.0 torchvision==0.4.0    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 22kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/e6/a564eba563f7ff53aa7318ff6aaa5bd8385cbda39ed55ba471e95af27d19/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.2.0) (1.19.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.15.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.2.0 torchvision-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlgkKV1lK591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "342921f4-d504-434b-d534-538ea0cd5044"
      },
      "source": [
        "!pip install Pillow==5.2.0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==5.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 15.3MB/s \n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed Pillow-5.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZshH0u2dbWb"
      },
      "source": [
        "# LOAD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVAi4Q6adUeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6665e08c-e862-4b21-9aed-a13c50f92596"
      },
      "source": [
        "cd /content/tirg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tirg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNn9zPOksjqu"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "from tools import pkl\n",
        "import time\n",
        "from test_retrieval import test\n",
        "from main import load_dataset, create_model_and_optimizer\n",
        "from LSH import create_hash_table"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD8iosGbdh1O"
      },
      "source": [
        "class Opt:\n",
        "    def __init__(self):\n",
        "        self.dataset = \"fashion200k\"\n",
        "        self.dataset_path = \"/content/Fashion200k\"\n",
        "        self.batch_size = 32\n",
        "        self.embed_dim = 512\n",
        "        self.hashing = True\n",
        "        self.retrieve_by_random = True\n",
        "        self.model = \"tirg\"\n",
        "        self.learning_rate = 1e-2\n",
        "        self.weight_decay = 1e-6\n",
        "        self.pretrained_model = \"/content/best_checkpoint.pth\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdB0YklCdkpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dfe5908-da9e-4f5e-9431-2818affb19e5"
      },
      "source": [
        "opt = Opt()\n",
        "trainset, testset = load_dataset(opt)\n",
        "model, _ = create_model_and_optimizer(opt, [t for t in trainset.get_all_texts()])\n",
        "model.eval()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading dataset  fashion200k\n",
            "read dress_train_detect_all.txt\n",
            "read skirt_train_detect_all.txt\n",
            "read top_train_detect_all.txt\n",
            "read jacket_train_detect_all.txt\n",
            "read pants_train_detect_all.txt\n",
            "Fashion200k: 172049 images\n",
            "53099 unique captions\n",
            "Modifiable images 106464\n",
            "read pants_test_detect_all.txt\n",
            "read dress_test_detect_all.txt\n",
            "read top_test_detect_all.txt\n",
            "read skirt_test_detect_all.txt\n",
            "read jacket_test_detect_all.txt\n",
            "Fashion200k: 29789 images\n",
            "trainset size: 172049\n",
            "testset size: 29789\n",
            "Creating model and optimizer for tirg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 161MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load checkpoint from /content/best_checkpoint.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TIRG(\n",
              "  (normalization_layer): NormalizationLayer()\n",
              "  (soft_triplet_loss): TripletLoss()\n",
              "  (img_model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): GlobalAvgPool2d()\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (text_model): TextLSTMModel(\n",
              "    (embedding_layer): Embedding(5590, 512)\n",
              "    (lstm): LSTM(512, 512)\n",
              "    (fc_output): Sequential(\n",
              "      (0): Dropout(p=0.1, inplace=False)\n",
              "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (gated_feature_composer): Sequential(\n",
              "    (0): ConCatModule()\n",
              "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  )\n",
              "  (res_info_composer): Sequential(\n",
              "    (0): ConCatModule()\n",
              "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIel_LjVIV9E"
      },
      "source": [
        "#Pre-computed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd19maqUIamE"
      },
      "source": [
        "##Tính các vector đặc trưng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S-Bs8H-jVI5"
      },
      "source": [
        "Compute all images feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mS7tC5-hxbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ce5b92-e6d5-408b-c7f3-5b0f12b4bf7b"
      },
      "source": [
        "all_imgs = []\n",
        "imgs = []\n",
        "for i in tqdm(range(len(testset.imgs))):\n",
        "    imgs += [testset.get_img(i)]\n",
        "    if len(imgs) >= opt.batch_size or i == len(testset.imgs) - 1:\n",
        "        if 'torch' not in str(type(imgs[0])):\n",
        "            imgs = [torch.from_numpy(d).float() for d in imgs]\n",
        "        imgs = torch.stack(imgs).float()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            imgs = torch.autograd.Variable(imgs).cuda()\n",
        "        else:\n",
        "            imgs = torch.autograd.Variable(imgs).cpu()\n",
        "\n",
        "        imgs = model.extract_img_feature(imgs).data.cpu().numpy()\n",
        "        all_imgs += [imgs]\n",
        "        imgs = []\n",
        "\n",
        "all_imgs = np.concatenate(all_imgs)\n",
        "all_captions = [img['captions'][0] for img in testset.imgs]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 29789/29789 [04:41<00:00, 105.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypAlOVCIc2v7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162ad067-0f42-4a83-8b25-234293d82e9c"
      },
      "source": [
        "def save_normalize_all_imgs_feature():\n",
        "    all_imgs = pkl.pkl_load(\"/content/drive/MyDrive/TIRG/pkl_ver3/all_imgs.pkl\")\n",
        "    for i in tqdm(range(all_imgs.shape[0])):\n",
        "        all_imgs /= np.linalg.norm(all_imgs[i,:])\n",
        "\n",
        "save_normalize_all_imgs_feature()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 29789/29789 [02:47<00:00, 177.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekJvwwFyjzwN"
      },
      "source": [
        "Compute all queries feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuWzN0pBj5Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2712f953-eff2-45c9-9ef6-3a8e8c79e8d0"
      },
      "source": [
        "imgs = []\n",
        "mods = []\n",
        "all_queries = []\n",
        "test_queries = testset.get_test_queries()\n",
        "for t in tqdm(test_queries):\n",
        "    imgs += [testset.get_img(t['source_img_id'])]\n",
        "    mods += [t['mod']['str']]\n",
        "    if len(imgs) >= opt.batch_size or t is test_queries[-1]:\n",
        "        if 'torch' not in str(type(imgs[0])):\n",
        "            imgs = [torch.from_numpy(d).float() for d in imgs]\n",
        "        imgs = torch.stack(imgs).float()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            imgs = torch.autograd.Variable(imgs).cuda()\n",
        "        else:\n",
        "            imgs = torch.autograd.Variable(imgs).cpu()\n",
        "\n",
        "        mods = [t for t in mods]\n",
        "        f = model.compose_img_text(imgs, mods).data.cpu().numpy()\n",
        "        all_queries += [f]\n",
        "        imgs = []\n",
        "        mods = []\n",
        "\n",
        "all_queries = np.concatenate(all_queries)\n",
        "all_target_captions = [t['target_caption'] for t in test_queries]\n",
        "img_ids = [t[\"source_img_id\"] for t in test_queries]\n",
        "mods = [t[\"mod\"][\"str\"] for t in test_queries]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 17/33480 [00:00<03:20, 166.62it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "100%|██████████| 33480/33480 [04:21<00:00, 128.08it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRzHKGmkh2YJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124bc441-5acd-4fd8-c7b4-16fd283c7323"
      },
      "source": [
        "def save_normalize_all_queries_feature():\n",
        "    for i in tqdm(range(all_queries.shape[0])):\n",
        "        all_queries /= np.linalg.norm(all_queries[i,:])\n",
        "\n",
        "save_normalize_all_queries_feature()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 33480/33480 [03:32<00:00, 157.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7_VsLd8sr3i"
      },
      "source": [
        "##Hoặc sử dụng lại các pre-computed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Q64sjm0yy7"
      },
      "source": [
        "test_queries = testset.get_test_queries()\n",
        "all_queries = pkl.pkl_load(\"/content/pkls/all_norm_queries_feature.pkl\")\n",
        "all_target_captions = pkl.pkl_load(\"/content/pkls/all_target_captions.pkl\")\n",
        "all_imgs = pkl.pkl_load(\"/content/pkls/all_norm_imgs_feature.pkl\")\n",
        "all_captions = pkl.pkl_load(\"/content/pkls/all_captions.pkl\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIQagWaKmirM"
      },
      "source": [
        "# Create random queries\n",
        "np.random.seed(0)\n",
        "id_random = np.random.choice(all_queries.shape[0], 5000)\n",
        "queries_feature = []\n",
        "for id in id_random:\n",
        "    queries_feature += [all_queries[id]]\n",
        "\n",
        "queries_feature = np.array(queries_feature)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08HVkeSij9ay"
      },
      "source": [
        "# Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80vLcayhfA5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cd0ef8-d238-4cab-9cd2-c586dce812a7"
      },
      "source": [
        "tic = time.time()\n",
        "sims = queries_feature.dot(all_imgs.T)\n",
        "for i, t in enumerate(test_queries):\n",
        "\ttry:\n",
        "\t\tsims[i, t[\"source_img_id\"]] = -10e10  # remove query image\n",
        "\texcept:\n",
        "\t\tpass\n",
        "\n",
        "nn_result = [np.argsort(-sims[i, :])[:110] for i in range(sims.shape[0])]\n",
        "out = []\n",
        "nn_result = [[all_captions[nn] for nn in nns] for nns in nn_result]\n",
        "for k in [1, 5, 10, 50, 100]:\n",
        "# for k in [100]:\n",
        "    r = 0.0\n",
        "    # for i, nns in enumerate(nn_result):\n",
        "    for id, nns in zip(id_random, nn_result):\n",
        "        if all_target_captions[id] in nns[:k]:\n",
        "            r += 1\n",
        "    r /= len(nn_result)\n",
        "    out += [('recall_top' + str(k) + '_correct_composition', r)]\n",
        "tac = time.time()\n",
        "print(out)\n",
        "print(f\"{round(tac - tic, 3)}s\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('recall_top1_correct_composition', 0.003), ('recall_top5_correct_composition', 0.0204), ('recall_top10_correct_composition', 0.0734), ('recall_top50_correct_composition', 0.2406), ('recall_top100_correct_composition', 0.3026)]\n",
            "14.174s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd8cl_aSqIhX"
      },
      "source": [
        "# Hashing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HtxJRBtqOeG"
      },
      "source": [
        "def compute_similary_by_hasing(all_imgs_feature, queries_feature, test_queries):\n",
        "\thash_table = create_hash_table(all_imgs_feature, 12, 512)\n",
        "\tsims = []\n",
        "\tfor i, query in enumerate(queries_feature):\n",
        "\t\tidx_imgs = hash_table.__getitem__(query)\n",
        "\t\tspatial_search = np.array([all_imgs_feature[i] for i in idx_imgs])\n",
        "\t\tif spatial_search.shape[0] != 0:\n",
        "\t\t\tdis_value = query.dot(spatial_search.T)\n",
        "\t\t\tsim = np.full(all_imgs_feature.shape[0], -10e10)\n",
        "\t\t\tfor i in idx_imgs:\n",
        "\t\t\t\tsim[i] = dis_value[0]\n",
        "\t\t\t\tdis_value = dis_value[1:]\n",
        "\t\telse:\n",
        "\t\t\tsim = query.dot(all_imgs_feature.T)\n",
        "\n",
        "\t\tsim[test_queries[i]['source_img_id']] = -10e10\n",
        "\t\tsims += [sim]\n",
        "\n",
        "\treturn np.array(sims)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSgb4u1eqSno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd872d3-12e5-4320-924d-e4c4cef14616"
      },
      "source": [
        "tic = time.time()\n",
        "sims = compute_similary_by_hasing(all_imgs, queries_feature, test_queries)\n",
        "nn_result = [np.argsort(-sims[i, :])[:100] for i in range(sims.shape[0])]\n",
        "out = []\n",
        "nn_result = [[all_captions[nn] for nn in nns] for nns in nn_result]\n",
        "for k in [1, 5, 10, 50, 100]:\n",
        "# for k in [100]:\n",
        "    r = 0.0\n",
        "# for i, nns in enumerate(nn_result):\n",
        "    for id, nns in zip(id_random, nn_result):\n",
        "        if all_target_captions[id] in nns[:k]:\n",
        "            r += 1\n",
        "    r /= len(nn_result)\n",
        "    out += [('recall_top' + str(k) + '_correct_composition', r)]\n",
        "tac = time.time()\n",
        "print(out)\n",
        "print(f\"{round(tac - tic, 3)}s\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('recall_top1_correct_composition', 0.0224), ('recall_top5_correct_composition', 0.0502), ('recall_top10_correct_composition', 0.0842), ('recall_top50_correct_composition', 0.1908), ('recall_top100_correct_composition', 0.2366)]\n",
            "14.965s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}