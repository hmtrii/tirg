{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compute_recall.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmtrii/tirg/blob/main/Compute_recall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPTV_2MvyvWG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLwLuW2_dWRp"
      },
      "source": [
        "# INSTALL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AfCDwglHa42"
      },
      "source": [
        "!git clone https://github.com/hmtrii/tirg.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFtMdH2JL0t5"
      },
      "source": [
        "!rm -rf /content/Fashion200k\n",
        "!mkdir /content/Fashion200k\n",
        "!cp -r /content/drive/MyDrive/TIRG/dataset/fashion-200k/labels /content/Fashion200k\n",
        "!cp /content/drive/MyDrive/TIRG/dataset/test_queries.txt /content/Fashion200k\n",
        "!mkdir /content/Fashion200k/women"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udvOUNWT3JxZ"
      },
      "source": [
        "!tar -xf /content/drive/MyDrive/TIRG/dataset/fashion-200k/women.tar.gz -C /content/Fashion200k/women"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9b8NIwraH8L"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RarrJevA66j8"
      },
      "source": [
        "!pip install torch==1.2.0 torchvision==0.4.0    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlgkKV1lK591"
      },
      "source": [
        "!pip install Pillow==5.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZshH0u2dbWb"
      },
      "source": [
        "# LOAD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVAi4Q6adUeR"
      },
      "source": [
        "cd /content/tirg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNn9zPOksjqu"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "from tools import pkl\n",
        "import time\n",
        "from test_retrieval import test\n",
        "from main import load_dataset, create_model_and_optimizer\n",
        "from LSH import create_hash_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD8iosGbdh1O"
      },
      "source": [
        "class Opt:\n",
        "    def __init__(self):\n",
        "        self.dataset = \"fashion200k\"\n",
        "        self.dataset_path = \"/content/Fashion200k\"\n",
        "        self.batch_size = 32\n",
        "        self.embed_dim = 512\n",
        "        self.hashing = True\n",
        "        self.retrieve_by_random = True\n",
        "        self.model = \"tirg\"\n",
        "        self.learning_rate = 1e-2\n",
        "        self.weight_decay = 1e-6\n",
        "        self.pretrained_model = \"/content/drive/MyDrive/TIRG/runs/exp3/best_checkpoint.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdB0YklCdkpC"
      },
      "source": [
        "opt = Opt()\n",
        "trainset, testset = load_dataset(opt)\n",
        "model, _ = create_model_and_optimizer(opt, [t for t in trainset.get_all_texts()])\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S-Bs8H-jVI5"
      },
      "source": [
        "Compute all images feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mS7tC5-hxbv"
      },
      "source": [
        "all_imgs = []\n",
        "imgs = []\n",
        "for i in tqdm(range(len(testset.imgs))):\n",
        "    imgs += [testset.get_img(i)]\n",
        "    if len(imgs) >= opt.batch_size or i == len(testset.imgs) - 1:\n",
        "        if 'torch' not in str(type(imgs[0])):\n",
        "            imgs = [torch.from_numpy(d).float() for d in imgs]\n",
        "        imgs = torch.stack(imgs).float()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            imgs = torch.autograd.Variable(imgs).cuda()\n",
        "        else:\n",
        "            imgs = torch.autograd.Variable(imgs).cpu()\n",
        "\n",
        "        imgs = model.extract_img_feature(imgs).data.cpu().numpy()\n",
        "        all_imgs += [imgs]\n",
        "        imgs = []\n",
        "all_imgs = np.concatenate(all_imgs)\n",
        "all_captions = [img['captions'][0] for img in testset.imgs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC9pJr23eLkg"
      },
      "source": [
        "pkl.pkl_save(\"/content/all_captions.pkl\", all_captions)\n",
        "pkl.pkl_save(\"/content/all_imgs.pkl\", all_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypAlOVCIc2v7"
      },
      "source": [
        "def save_normalize_all_imgs_feature():\n",
        "    all_imgs_feature = pkl.pkl_load(\"/content/all_imgs.pkl\")\n",
        "    for i in tqdm(range(all_imgs_feature.shape[0])):\n",
        "        all_imgs_feature /= np.linalg.norm(all_imgs_feature[i,:])\n",
        "\n",
        "    pkl.pkl_save(\"/content/all_norm_imgs_feature.pkl\", all_imgs_feature)\n",
        "\n",
        "save_normalize_all_imgs_feature()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekJvwwFyjzwN"
      },
      "source": [
        "Compute all queries feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuWzN0pBj5Or"
      },
      "source": [
        "imgs = []\n",
        "mods = []\n",
        "all_queries = []\n",
        "test_queries = testset.get_test_queries()\n",
        "for t in tqdm(test_queries):\n",
        "    imgs += [testset.get_img(t['source_img_id'])]\n",
        "    mods += [t['mod']['str']]\n",
        "    if len(imgs) >= opt.batch_size or t is test_queries[-1]:\n",
        "        if 'torch' not in str(type(imgs[0])):\n",
        "            imgs = [torch.from_numpy(d).float() for d in imgs]\n",
        "        imgs = torch.stack(imgs).float()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            imgs = torch.autograd.Variable(imgs).cuda()\n",
        "        else:\n",
        "            imgs = torch.autograd.Variable(imgs).cpu()\n",
        "\n",
        "        mods = [t for t in mods]\n",
        "        f = model.compose_img_text(imgs, mods).data.cpu().numpy()\n",
        "        all_queries += [f]\n",
        "        imgs = []\n",
        "        mods = []\n",
        "all_queries = np.concatenate(all_queries)\n",
        "all_target_captions = [t['target_caption'] for t in test_queries]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zgxhZ3FhZdt"
      },
      "source": [
        "pkl.pkl_save(\"/content/all_queries.pkl\", all_queries)\n",
        "pkl.pkl_save(\"/content/all_target_captions.pkl\", all_target_captions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRzHKGmkh2YJ"
      },
      "source": [
        "def save_normalize_all_queries_feature():\n",
        "    all_imgs_feature = pkl.pkl_load(\"/content/all_queries.pkl\")\n",
        "    for i in tqdm(range(all_imgs_feature.shape[0])):\n",
        "        all_imgs_feature /= np.linalg.norm(all_imgs_feature[i,:])\n",
        "\n",
        "    pkl.pkl_save(\"/content/all_norm_queries_feature.pkl\", all_imgs_feature)\n",
        "save_normalize_all_queries_feature()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7_VsLd8sr3i"
      },
      "source": [
        "Use pre-computed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtI9V3I_jZlx"
      },
      "source": [
        "cp /content/*.pkl -d /content/drive/MyDrive/TIRG/pkl_ver3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Q64sjm0yy7"
      },
      "source": [
        "test_queries = testset.get_test_queries()\n",
        "all_queries = pkl.pkl_load(\"/content/drive/MyDrive/TIRG/pkl_ver3/all_norm_queries_feature.pkl\")\n",
        "all_target_captions = pkl.pkl_load(\"/content/drive/MyDrive/TIRG/pkl_ver3/all_target_captions.pkl\")\n",
        "all_imgs = pkl.pkl_load(\"/content/drive/MyDrive/TIRG/pkl_ver3/all_norm_imgs_feature.pkl\")\n",
        "all_captions = pkl.pkl_load(\"/content/drive/MyDrive/TIRG/pkl_ver3/all_captions.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIQagWaKmirM"
      },
      "source": [
        "# Create random queries\n",
        "np.random.seed(0)\n",
        "id_random = np.random.choice(all_queries.shape[0], 5000)\n",
        "queries_feature = []\n",
        "for id in id_random:\n",
        "    queries_feature += [all_queries[id]]\n",
        "\n",
        "queries_feature = np.array(queries_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08HVkeSij9ay"
      },
      "source": [
        "# Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80vLcayhfA5z"
      },
      "source": [
        "tic = time.time()\n",
        "sims = queries_feature.dot(all_imgs.T)\n",
        "for i, t in enumerate(test_queries):\n",
        "\ttry:\n",
        "\t\tsims[i, t[\"source_img_id\"]] = -10e10  # remove query image\n",
        "\texcept:\n",
        "\t\tpass\n",
        "\n",
        "nn_result = [np.argsort(-sims[i, :])[:110] for i in range(sims.shape[0])]\n",
        "out = []\n",
        "nn_result = [[all_captions[nn] for nn in nns] for nns in nn_result]\n",
        "for k in [1, 5, 10, 50, 100]:\n",
        "# for k in [100]:\n",
        "    r = 0.0\n",
        "    # for i, nns in enumerate(nn_result):\n",
        "    for id, nns in zip(id_random, nn_result):\n",
        "        if all_target_captions[id] in nns[:k]:\n",
        "            r += 1\n",
        "    r /= len(nn_result)\n",
        "    out += [('recall_top' + str(k) + '_correct_composition', r)]\n",
        "tac = time.time()\n",
        "print(out)\n",
        "print(f\"{round(tac - tic, 3)}s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd8cl_aSqIhX"
      },
      "source": [
        "# Hashing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HtxJRBtqOeG"
      },
      "source": [
        "def compute_similary_by_hasing(all_imgs_feature, queries_feature, test_queries):\n",
        "\thash_table = create_hash_table(all_imgs_feature, 12, 512)\n",
        "\tsims = []\n",
        "\tfor i, query in enumerate(queries_feature):\n",
        "\t\tidx_imgs = hash_table.__getitem__(query)\n",
        "\t\tspatial_search = np.array([all_imgs_feature[i] for i in idx_imgs])\n",
        "\t\tif spatial_search.shape[0] != 0:\n",
        "\t\t\tdis_value = query.dot(spatial_search.T)\n",
        "\t\t\tsim = np.full(all_imgs_feature.shape[0], -10e10)\n",
        "\t\t\tfor i in idx_imgs:\n",
        "\t\t\t\tsim[i] = dis_value[0]\n",
        "\t\t\t\tdis_value = dis_value[1:]\n",
        "\t\telse:\n",
        "\t\t\tsim = query.dot(all_imgs_feature.T)\n",
        "\n",
        "\t\tsim[test_queries[i]['source_img_id']] = -10e10\n",
        "\t\tsims += [sim]\n",
        "\n",
        "\treturn np.array(sims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSgb4u1eqSno"
      },
      "source": [
        "tic = time.time()\n",
        "sims = compute_similary_by_hasing(all_imgs, queries_feature, test_queries)\n",
        "nn_result = [np.argsort(-sims[i, :])[:100] for i in range(sims.shape[0])]\n",
        "out = []\n",
        "nn_result = [[all_captions[nn] for nn in nns] for nns in nn_result]\n",
        "for k in [1, 5, 10, 50, 100]:\n",
        "# for k in [100]:\n",
        "    r = 0.0\n",
        "# for i, nns in enumerate(nn_result):\n",
        "    for id, nns in zip(id_random, nn_result):\n",
        "        if all_target_captions[id] in nns[:k]:\n",
        "            r += 1\n",
        "    r /= len(nn_result)\n",
        "    out += [('recall_top' + str(k) + '_correct_composition', r)]\n",
        "tac = time.time()\n",
        "print(out)\n",
        "print(f\"{round(tac - tic, 3)}s\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}